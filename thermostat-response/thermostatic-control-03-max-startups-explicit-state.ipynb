{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermostatic Control - Max Start-ups with explicit state\n",
    "\n",
    "Here we make and enviroment like the bang-bang controller prior, but with a limit on the number of times it can start up in a given window.  For completeness, here are the features of this environment:\n",
    "\n",
    "- Has a response time constant tau that dictates how fast the system responds to heater on/off states.\n",
    "- Keeps track of how many times it has turned on in a past window of time, and limits it, otherwise, we consider it a failure.  The idea is that toggling on too many times will damage/break equipment, and we model that here.\n",
    "- We also expose the 'number of startups left in window' as a state parameter.\n",
    "- Violation of this constraint, for training purposes, results in a very negative reward.  We could terminate the episode as well, but I have found better luck training a model by allowing the episode to continue with a very negative penalty for constraint violation.\n",
    "\n",
    "A point of emphasis here is on hitting the failure condition while training.  Depending on the circumstances, failure while training can be either cheap or expensive.  When training RL to win at \"Go\", many millions of games were played, and games that were lost provided some of the signal for learning a winning policy.  But those game losses were cheap -- nothing broke and no one was harmed.  However, learning policies in industrial settings or health care can be expensive or dangerous to people.  A sub-optimal policy in the midst of training is sub-optimal because it will make a bad decision that can cause harm to a machine or person.  This means that during training, episodes that terminate in failure are expensive.  Here we make a model to give us insight into this phenomenon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "\n",
    "Here we code the environment class to use.  It will include logic that terminates an episode before it reaches its `max_timestep` limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorforce.environments import Environment\n",
    "from tensorforce.agents import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermostatEnvironment(Environment):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ## Some initializations.  Will eventually parameterize this in the constructor.\n",
    "        self.tau = 3.0\n",
    "        self.current_temp = 0.0\n",
    "        self.timestep = 0\n",
    "        self.max_timestep = 100\n",
    "        self.exceed_toggle_on_reward = -10.0\n",
    "        \n",
    "        ## Heater on states\n",
    "        self.last_heater_state = 0\n",
    "        self.max_toggle_ons = 3 # max number of times you can turn heater on...\n",
    "        self.toggle_ons_left = self.max_toggle_ons # Track toggle ons left in window\n",
    "        self.window_toggle_ons = 10 # Window of time over which you can use your max_toggle_ons\n",
    "        self.off_to_on = [] # timesteps at which state went off to on\n",
    "    \n",
    "        super().__init__()\n",
    "\n",
    "    def states(self):\n",
    "        \"\"\"Two state components:\n",
    "               1. current_temp\n",
    "               2. toggle_ons_left\n",
    "        \"\"\"\n",
    "        return dict(type='float', shape=(2,))\n",
    "\n",
    "    def actions(self):\n",
    "        return dict(type='int', num_values=2)\n",
    "\n",
    "    # Optional, should only be defined if environment has a natural maximum\n",
    "    # episode length\n",
    "    def max_episode_timesteps(self):\n",
    "        # return super().max_episode_timesteps()\n",
    "        return self.max_timestep\n",
    "\n",
    "    # Optional\n",
    "    def close(self):\n",
    "        super().close()\n",
    "\n",
    "    def reset(self):\n",
    "        self.timestep = 0\n",
    "        self.last_heater_state = 0\n",
    "        self.off_to_on = []\n",
    "        self.toggle_ons_left = self.max_toggle_ons\n",
    "        self.current_temp = np.random.random(size=(1,))\n",
    "        return np.array([self.current_temp, self.toggle_ons_left], dtype=np.float)\n",
    "\n",
    "    def response(self, action):\n",
    "        \"\"\"Respond to an action.  When the action is 1, the temperature\n",
    "        exponentially decays approaches 1.0.  When the action is 0,\n",
    "        the current temperature decays towards 0.0.\n",
    "        \"\"\"\n",
    "        return action + (self.current_temp - action) * math.exp(-1.0 / self.tau)\n",
    "\n",
    "    def reward_compute(self):\n",
    "        \"\"\" The reward here is 0 if the current temp is between 0.4 and 0.6,\n",
    "        else it is distance the temp is away from the 0.4 or 0.6 boundary.\n",
    "        \"\"\"\n",
    "        delta = abs(self.current_temp - 0.5)\n",
    "        if delta < 0.1:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return -delta[0] + 0.1\n",
    "\n",
    "    def execute(self, actions):\n",
    "        ## Check the action is either 0 or 1 -- heater on or off.\n",
    "        assert actions == 0 or actions == 1\n",
    "\n",
    "        ## Increment timestamp\n",
    "        self.timestep += 1\n",
    "        \n",
    "        ## Update the current_temp\n",
    "        self.current_temp = self.response(actions)\n",
    "\n",
    "        ## Update off_to_ons if necessary\n",
    "        if actions == 1 and self.last_heater_state == 0:\n",
    "            self.off_to_on += [self.timestep]\n",
    "            \n",
    "        ## Update last heater state to current state\n",
    "        self.last_heater_state = actions\n",
    "        \n",
    "        ## Check if we have violated max_startups, return as necessary\n",
    "        ## Make a list of the events within the window\n",
    "        lstWindowEvents = [e for e in self.off_to_on\n",
    "                              if self.timestep - e <= self.window_toggle_ons]\n",
    "\n",
    "        ## Calculate number of toggle_ons_left\n",
    "        self.toggle_ons_left = self.max_toggle_ons - len(lstWindowEvents)\n",
    "        \n",
    "        ## Conditional returns\n",
    "        ##\n",
    "        ## If we have done too many startups, DON'T end episode, but return big penalty\n",
    "        if self.toggle_ons_left < 0:\n",
    "            return np.array([self.current_temp, self.toggle_ons_left], dtype=np.float), False, self.exceed_toggle_on_reward\n",
    "        \n",
    "        ## If we exceed max_timestamps, end episode.\n",
    "        if self.timestep > self.max_episode_timesteps():\n",
    "            return np.array([self.current_temp, self.toggle_ons_left], dtype=np.float), True, self.reward_compute()\n",
    "        \n",
    "        ## Default return\n",
    "        return np.array([self.current_temp, self.toggle_ons_left], dtype=np.float), False, self.reward_compute()\n",
    "\n",
    "## Instantiate environment object\n",
    "# environment = ThermostatEnvironment()\n",
    "environment = environment = Environment.create(\n",
    "    environment=ThermostatEnvironment,\n",
    "    max_episode_timesteps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47502231 3.        ]\n",
      "(array([0.62383705, 2.        ]), 0, -0.02383705046748083)\n",
      "(array([0.44699878, 2.        ]), 0, 1.0)\n",
      "(array([0.60375731, 1.        ]), 0, -0.003757310623014515)\n",
      "(array([0.43261102, 1.        ]), 0, 1.0)\n",
      "(array([0.59344803, 0.        ]), 0, 1.0)\n",
      "(array([0.42522409, 0.        ]), 0, 1.0)\n",
      "(array([ 0.58815507, -1.        ]), 0, -10.0)\n",
      "(array([ 0.70490021, -1.        ]), 0, -10.0)\n",
      "(array([ 0.78855176, -1.        ]), 0, -10.0)\n",
      "[1, 3, 5, 7]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "## Initialize\n",
    "## Test the environment does what I expect it to\n",
    "print(environment.reset())\n",
    "\n",
    "print(environment.execute(1))\n",
    "print(environment.execute(0))\n",
    "print(environment.execute(1))\n",
    "print(environment.execute(0))\n",
    "print(environment.execute(1))\n",
    "print(environment.execute(0))\n",
    "print(environment.execute(1))\n",
    "print(environment.execute(1))\n",
    "print(environment.execute(1))\n",
    "print(environment.environment.off_to_on)\n",
    "print(environment.timestep)\n",
    "print(environment.environment.timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "## Agent setup\n",
    "## This one works\n",
    "# agent = Agent.create(\n",
    "#     agent='tensorforce', environment=environment, update=32,\n",
    "#     objective='policy_gradient', reward_estimation=dict(horizon=25)\n",
    "# )\n",
    "\n",
    "## PPO\n",
    "## So far, this results in an agent that just keeps the heater on.\n",
    "# agent = Agent.create(\n",
    "#     agent='ppo', environment=environment, batch_size=50, learning_rate=1e-3,\n",
    "#     exploration=0.1\n",
    "# )\n",
    "\n",
    "## Vanilla Policy Gradient\n",
    "agent = Agent.create(\n",
    "    agent='vpg', environment=environment, batch_size=10, learning_rate=1e-3,\n",
    "    exploration=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "for _ in range(200):\n",
    "    states = environment.reset()\n",
    "    terminal = False\n",
    "    while not terminal:\n",
    "        actions = agent.act(states=states)\n",
    "        states, terminal, reward = environment.execute(actions=actions)\n",
    "        #print(f\"{states}, {terminal}, {reward}\")\n",
    "        agent.observe(terminal=terminal, reward=reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81888633 3.        ]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Initialize\n",
    "print(environment.reset())\n",
    "\n",
    "## Creation of the environment via Environment.create() creates\n",
    "## a wrapper class around the original Environment defined here.\n",
    "## That wrapper mainly keeps track of the number of timesteps.\n",
    "## In order to alter the attributes of your instance of the original\n",
    "## class, like to set the initial temp to a custom value, like here,\n",
    "## you need to access the `environment` member of this wrapped class.\n",
    "## That is why you see the way to set the current_temp like below.\n",
    "# environment.environment.current_temp = np.array([1.0])\n",
    "# states = environment.environment.current_temp\n",
    "\n",
    "internals = agent.initial_internals()\n",
    "terminal = False\n",
    "\n",
    "### Run an episode\n",
    "temp = [environment.environment.current_temp[0]]\n",
    "while not terminal:\n",
    "    actions, internals = agent.act(states=states, internals=internals, evaluation=True)\n",
    "    states, terminal, reward = environment.execute(actions=actions)\n",
    "    temp += [states[0]]\n",
    "\n",
    "# print(temp)\n",
    "print(environment.environment.off_to_on)\n",
    "\n",
    "### Plot the run\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax=plt.subplot()\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "plt.plot(range(len(temp)), temp)\n",
    "plt.hlines(y=0.4, xmin=0, xmax=99, color='r')\n",
    "plt.hlines(y=0.6, xmin=0, xmax=99, color='r')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Temperature vs. Timestep')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
